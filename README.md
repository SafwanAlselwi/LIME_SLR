# A Systematic Literature Review of Model Agnostic Approach in Medical Imaging

**Abstract**
<br>
The interpretability and explainability of machine learning and artificial intelligence systems are critical for generating trust in their outcomes in fields such as medicine and healthcare. Errors generated by these systems, such as inaccurate diagnoses or treatments, can have serious and even life-threatening effects on patients. Explainable Artificial Intelligence (XAI) is emerging as an increasingly significant area of research nowadays, focusing on the black-box aspect of sophisticated and difficult-to-interpret machine learning algorithms. XAI techniques such as Local Interpretable Model-Agnostic Explanations (LIME) can give explanations for these models, raising confidence in the systems and improving trust in their predictions. Numerous works have been published that respond to medical problems through the use of machine learning models in conjunction with XAI algorithms to give interpretability and explainability. The primary objective of the study is to evaluate the performance of the model agnostic approach and newly emerging LIME techniques within healthcare domains that require more attention in the realm of XAI research. n this study, a systematic search was conducted in numerous databases (Scopus, Web of Science, IEEE Xplore, ScienceDirect, MDPI, and PubMed ) that identified 1614 peer-reviewed articles (77 selected) published between 2019 and 2023.


**Data Availability**
<br>
The Microsoft Excel file utilized for this systematic literature review will be made publicly accessible in this repository following the acceptance of our manuscript.
